{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technologies QA with pdf data\n",
    "\n",
    "* Date: Dec 03, 2023\n",
    "* Author: Dawan Savage Bell\n",
    "* W0465310\n",
    "* Mileston 10\n",
    "\n",
    "\n",
    "\n",
    "### Resources used \n",
    "https://medium.com/@alinaeem_57283/building-a-pdf-querying-bot-with-langchain-edb71ebedcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pulsar-client (from versions: none)\n",
      "ERROR: No matching distribution found for pulsar-client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests>=2.28 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from chromadb) (2.5.2)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.24.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.1.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from chromadb) (4.8.0)\n",
      "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.17-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pydantic<2.0,>=1.9 (from chromadb)\n",
      "  Using cached pydantic-1.10.13-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.11-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached chromadb-0.4.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.9-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from chromadb) (1.26.0)\n",
      "  Using cached chromadb-0.4.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pandas>=1.3 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from chromadb) (2.1.1)\n",
      "Collecting chroma-hnswlib==0.7.1 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.3.29-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting hnswlib>=0.7 (from chromadb)\n",
      "  Using cached hnswlib-0.8.0.tar.gz (36 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting clickhouse-connect>=0.5.7 (from chromadb)\n",
      "  Using cached clickhouse_connect-0.6.22-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting duckdb>=0.7.1 (from chromadb)\n",
      "  Using cached duckdb-0.9.2.tar.gz (10.7 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fastapi==0.85.1 (from chromadb)\n",
      "  Using cached fastapi-0.85.1-py3-none-any.whl (55 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.27-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pydantic==1.9 (from chromadb)\n",
      "  Using cached pydantic-1.9.0-py3-none-any.whl (140 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.26-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.3.25-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Using cached chromadb-0.3.23-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting sentence-transformers>=2.2.2 (from chromadb)\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: certifi in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: urllib3>=1.26 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.18)\n",
      "Requirement already satisfied: pytz in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3.post1)\n",
      "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb)\n",
      "  Using cached zstandard-0.22.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting lz4 (from clickhouse-connect>=0.5.7->chromadb)\n",
      "  Using cached lz4-4.3.2.tar.gz (170 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting anyio<4.0.0,>=3.7.1 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=2.2.2->chromadb)\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: tqdm in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.66.1)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.22-py3-none-any.whl (69 kB)\n",
      "  Using cached chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
      "  Using cached chromadb-0.3.20-py3-none-any.whl (46 kB)\n",
      "  Using cached chromadb-0.3.18-py3-none-any.whl (46 kB)\n",
      "  Using cached chromadb-0.3.17-py3-none-any.whl (46 kB)\n",
      "  Using cached chromadb-0.3.16-py3-none-any.whl (46 kB)\n",
      "  Using cached chromadb-0.3.15-py3-none-any.whl (46 kB)\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached chromadb-0.3.14-py3-none-any.whl (45 kB)\n",
      "  Using cached chromadb-0.3.13-py3-none-any.whl (45 kB)\n",
      "  Using cached chromadb-0.3.12-py3-none-any.whl (45 kB)\n",
      "  Using cached chromadb-0.3.11-py3-none-any.whl (41 kB)\n",
      "  Using cached chromadb-0.3.10-py3-none-any.whl (40 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached chromadb-0.3.8-py3-none-any.whl (40 kB)\n",
      "  Using cached chromadb-0.3.7-py3-none-any.whl (39 kB)\n",
      "  Using cached chromadb-0.3.6-py3-none-any.whl (39 kB)\n",
      "  Using cached chromadb-0.3.5-py3-none-any.whl (38 kB)\n",
      "  Using cached chromadb-0.3.4-py3-none-any.whl (38 kB)\n",
      "  Using cached chromadb-0.3.3-py3-none-any.whl (38 kB)\n",
      "  Using cached chromadb-0.3.2-py3-none-any.whl (37 kB)\n",
      "Collecting pandas~=1.3 (from chromadb)\n",
      "  Using cached pandas-1.5.3.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: still running...\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting clickhouse-connect~=0.5.7 (from chromadb)\n",
      "  Using cached clickhouse-connect-0.5.25.tar.gz (70 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting duckdb~=0.5.1 (from chromadb)\n",
      "  Using cached duckdb-0.5.1.tar.gz (13.5 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fastapi~=0.85.1 (from chromadb)\n",
      "  Using cached fastapi-0.85.2-py3-none-any.whl (55 kB)\n",
      "Collecting uvicorn~=0.18.3 (from uvicorn[standard]~=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.1-py3-none-any.whl (37 kB)\n",
      "  Using cached chromadb-0.3.0-py3-none-any.whl (36 kB)\n",
      "  Using cached chromadb-0.2.0-py3-none-any.whl (36 kB)\n",
      "Collecting uuid~=1.30 (from chromadb)\n",
      "  Using cached uuid-1.30.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.1.0-py3-none-any.whl (34 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    chromadb 0.4.18 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.17 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.16 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.15 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.14 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.13 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.12 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.11 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.10 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.9 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.8 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.7 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.6 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.5 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.4 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.3 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.2 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.1 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.0 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.3.29 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.3.27 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.3.26 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.3.25 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.3.2 depends on numpy~=1.21.6\n",
      "    chromadb 0.3.1 depends on numpy~=1.21.6\n",
      "    chromadb 0.3.0 depends on numpy~=1.21.6\n",
      "    chromadb 0.2.0 depends on numpy~=1.21.6\n",
      "    chromadb 0.1.0 depends on numpy~=1.21.6\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install chromadb==0.1.0, chromadb==0.2.0, chromadb==0.3.0, chromadb==0.3.1, chromadb==0.3.2, chromadb==0.3.25, chromadb==0.3.26, chromadb==0.3.27, chromadb==0.3.29, chromadb==0.4.0, chromadb==0.4.1, chromadb==0.4.10, chromadb==0.4.11, chromadb==0.4.12, chromadb==0.4.13, chromadb==0.4.14, chromadb==0.4.15, chromadb==0.4.16, chromadb==0.4.17, chromadb==0.4.18, chromadb==0.4.2, chromadb==0.4.3, chromadb==0.4.4, chromadb==0.4.5, chromadb==0.4.6, chromadb==0.4.7, chromadb==0.4.8 and chromadb==0.4.9 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install pulsar-client\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Using cached unstructured-0.11.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-4.9.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 330.3 kB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.0/1.5 MB 326.8 kB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.1/1.5 MB 853.3 kB/s eta 0:00:02\n",
      "     -------- ------------------------------- 0.3/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 0.5/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.6/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting tabulate (from unstructured)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.9.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from unstructured) (0.6.3)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2023.6.15-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from unstructured) (1.26.0)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.5.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from unstructured) (4.8.0)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured)\n",
      "  Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from requests->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\savag\\appdata\\local\\anaconda3\\envs\\mad_scientist\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Using cached unstructured-0.11.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 122.9/199.4 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
      "Downloading lxml-4.9.3-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/3.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.6/3.8 MB 4.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.8/3.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.5/3.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.5/3.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.7/3.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.2/3.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 4.5 MB/s eta 0:00:00\n",
      "Using cached python_iso639-2023.6.15-py3-none-any.whl (275 kB)\n",
      "Downloading rapidfuzz-3.5.2-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 5.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 204.8/269.0 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 256.0/302.2 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 4.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993254 sha256=4564b46f982320637f61f51dace373dea4657c4612cfdb87168129ac94a019bd\n",
      "  Stored in directory: c:\\users\\savag\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, wrapt, tabulate, regex, rapidfuzz, python-magic, python-iso639, lxml, langdetect, joblib, emoji, click, chardet, backoff, nltk, unstructured\n",
      "Successfully installed backoff-2.2.1 chardet-5.2.0 click-8.1.7 emoji-2.9.0 filetype-1.2.0 joblib-1.3.2 langdetect-1.0.9 lxml-4.9.3 nltk-3.8.1 python-iso639-2023.6.15 python-magic-0.4.27 rapidfuzz-3.5.2 regex-2023.10.3 tabulate-0.9.0 unstructured-0.11.2 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip install unstructured\n",
    "# !pip install pypdf\n",
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install pdf2image\n",
    "# !pip install tiktoken\n",
    "# !pip install lark\n",
    "#!pip install pinecone-client\n",
    "!pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "    import json\n",
    "    import PyPDF2\n",
    "    import pinecone\n",
    "    \n",
    "    from tqdm.autonotebook import tqdm\n",
    "    from langchain import HuggingFaceHub\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "    \n",
    "    # selecting the embedding \n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    from langchain.vectorstores import Chroma, Pinecone\n",
    "    # expose the index in a retriever obj/instance\n",
    "    from langchain.chains import RetrievalQA\n",
    "    \n",
    "    print(\"imports completed\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment set\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"./keys/keys.json\") as f:\n",
    "        tokens = json.load(f)\n",
    "        open_token = tokens[\"open_ai_token\"]\n",
    "        pinecone_token = tokens[\"pine_cone_token\"]\n",
    "        pinecone_env = tokens[\"pine_cone_api_env\"]\n",
    "        os.environ['OPENAI_API_KEY'] = open_token\n",
    "        os.environ['PINECONE_API_KEY'] = pinecone_token\n",
    "        print(\"environment set\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"token not set\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(\"./docs/albert_einstein_relativity.pdf\")\n",
    "page_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './docs/albert_einstein_relativity.pdf', 'page': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data[1].page_content\n",
    "page_data[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 184 document(s) in the data\n",
      "There are 266 characters in the document\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(page_data)} document(s) in the data')\n",
    "print(f'There are {len(page_data[0].page_content)} characters in the document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the PDF\n",
    "* splitting by tokens due to LLM's having token limits.\n",
    "* When splitting by chunks, we are also counting the number of tokens. \n",
    "* splitting by characters passed in, chunk size measured by 'tiktoken' tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/albert_einstein_relativity.pdf\") as f:\n",
    "    #\n",
    "    relativity_pdf = PyPDF2.PdfReader(\"./docs/albert_einstein_relativity.pdf\")\n",
    "    # creating empty list to store the text from each page\n",
    "    text = \"\"\n",
    "    # iterating through each page in the pdf\n",
    "    for page in relativity_pdf.pages:\n",
    "        # extracting the text from each page\n",
    "        text += page.extract_text()\n",
    "\n",
    "# split the doc into \n",
    "# chunk size is the number of characters\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "# split the text into chunks\n",
    "chunks = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the \n",
      "simplest and most intelligible form, and on the \n",
      " \n",
      "1 The mathematical fundaments of the special theory of rela-\n",
      "tivity are to be found in the original papers of H. A. Lorentz, A. \n",
      "Einstein, H. Minkowski,* published under the title Das Relativitäts- \n",
      "prinzip (The Principle of Relativity) in B. G. Teubner’s collection \n",
      "of monographs Fortschritte der mathematischen Wissenschaften (Ad-\n",
      "vances in the Mathematical Sciences), also in M. Laue’s exhaustive \n",
      "book Das Relativitäts prinzip — published by Friedr. Vieweg & Son, \n",
      "Braunschweig. The general theory of relativity, together with the \n",
      "necessary parts of the theory of invariants, is dealt with in the \n",
      "author’s book Die Grundlagen der allgemeinen Relativitätstheorie \n",
      "(The Foundations of the General Theory of Relativity) — Joh. \n",
      "Ambr. Barth, 1916; this book assumes some familiarity with the \n",
      "special theory of relativity. \n",
      " \n",
      "v \n",
      " \n",
      "[* Minkowski‘ — J.M.] T vi                               RELATIVITY \n",
      " \n",
      "whole, in the sequence and connection in which \n",
      "they actually originated. In the interest of \n",
      "clearness, it appeared to me inevitable that I \n",
      "should repeat myself frequently, without paying \n",
      "the slightest attention to the elegance of the \n",
      "presentation. I adhered scrupulously to the \n",
      "precept of that brilliant theoretical physicist, \n",
      "L. Boltzmann, according to whom matters of \n",
      "elegance ought to be left to the tailor and to the \n",
      "cobbler.  I make no pretence of having with-\n",
      "held from the reader difficulties which are in-\n",
      "herent to the subject. On the other hand, I have \n",
      "purposely treated the empirical physical founda-\n",
      "tions of the theory in a “step-motherly” fashion, \n",
      "so that readers unfamiliar with physics may not \n",
      "feel like the wanderer who was unable to see the \n",
      "forest for trees. May the book bring some one \n",
      "a few happy hours of suggestive thought! \n",
      "A.  EINSTEIN \n",
      "December, 1916 \n",
      " \n",
      "NOTE  TO  THE  THIRD  EDITION \n",
      " \n",
      "N the present year (1918) an excellent and \n",
      "  detailed manual on the general theory of \n",
      "  relativity, written by H. Weyl, was pub-\n",
      "lished by the firm Julius Springer (Berlin). This \n",
      "book, entitled Raum — Zeit — Materie (Space —\n",
      "Time — Matter), may be warmly recommended \n",
      "to mathematicians and physicists. I  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "BIOGRAPHICAL  NOTE \n",
      " \n",
      "LBERT EINSTEIN is the son of German-\n",
      "  Jewish parents. He was born in 1879 in \n",
      "  the town of Ulm, Würtemberg, Germany. \n",
      "His schooldays were spent in Munich, where he \n",
      "attended the Gymnasium until his sixteenth year. \n",
      "After leaving school at Munich, he accompanied his \n",
      "parents to Milan, whence he proceeded to Switzer-\n",
      "land six months later to continue his studies.  \n",
      "From 1896 to 1900 Albert Einstein studied \n",
      "mathematics and physics at the Technical High \n",
      "School in Zurich, as he intended becoming a \n",
      "secondary school (Gymnasium) teacher. For \n",
      "some time afterwards he was a private tutor, \n",
      "and having meanwhile become naturalised, he \n",
      "obtained a post as engineer in the Swiss Patent \n",
      "Office in 1902, which position he occupied till 1909. \n",
      "The main ideas involved in the most important \n",
      "of Einstein’s theories date back to this period. \n",
      "Amongst these may be mentioned: The Special \n",
      "Theory of Relativity, Inertia of Energy, Theory of \n",
      "the Brownian Movement, and the Quantum-Law \n",
      "of the Emission and Absorption of Light (1905). \n",
      "These were followed some years later by the \n",
      " \n",
      "vii A viii                             REL\n"
     ]
    }
   ],
   "source": [
    "print(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Savag\\OneDrive\\Laboratory\\Github\\emergTech\\emergTech-llm-qa-pdf\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chunks[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mmetadata\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "chunks[1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vector Database using Pinecone\n",
    "* creates a local instance of a vector database after creating embeddings of the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:81\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Savag\\OneDrive\\Laboratory\\Github\\emergTech\\emergTech-llm-qa-pdf\\main.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# create a vector store\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m vector_store \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_texts(chunks, embeddings)\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:707\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[0;32m    676\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    687\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[0;32m    688\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \n\u001b[0;32m    690\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    708\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[0;32m    709\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[0;32m    710\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[0;32m    711\u001b[0m         client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[0;32m    712\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[0;32m    713\u001b[0m         collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[0;32m    714\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    715\u001b[0m     )\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m         ids \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid1()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:84\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import chromadb python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install chromadb`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_settings \u001b[39m=\u001b[39m client_settings\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "# create embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# create a vector store\n",
    "vector_store = Chroma.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Savag\\OneDrive\\Laboratory\\Github\\emergTech\\emergTech-llm-qa-pdf\\main.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create the vector store\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Savag/OneDrive/Laboratory/Github/emergTech/emergTech-llm-qa-pdf/main.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vector_store \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_texts(chunks, embeddings, index_name\u001b[39m=\u001b[39;49mindex_name)\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:421\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m pinecone_index \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_pinecone_index(index_name, pool_threads)\n\u001b[0;32m    419\u001b[0m pinecone \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 421\u001b[0m pinecone\u001b[39m.\u001b[39;49madd_texts(\n\u001b[0;32m    422\u001b[0m     texts,\n\u001b[0;32m    423\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[0;32m    424\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[0;32m    425\u001b[0m     namespace\u001b[39m=\u001b[39;49mnamespace,\n\u001b[0;32m    426\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    427\u001b[0m     embedding_chunk_size\u001b[39m=\u001b[39;49membeddings_chunk_size,\n\u001b[0;32m    428\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(upsert_kwargs \u001b[39mor\u001b[39;49;00m {}),\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    430\u001b[0m \u001b[39mreturn\u001b[39;00m pinecone\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:137\u001b[0m, in \u001b[0;36mPinecone.add_texts\u001b[1;34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m chunk_ids \u001b[39m=\u001b[39m ids[i : i \u001b[39m+\u001b[39m embedding_chunk_size]\n\u001b[0;32m    136\u001b[0m chunk_metadatas \u001b[39m=\u001b[39m metadatas[i : i \u001b[39m+\u001b[39m embedding_chunk_size]\n\u001b[1;32m--> 137\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_documents(chunk_texts)\n\u001b[0;32m    138\u001b[0m async_res \u001b[39m=\u001b[39m [\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index\u001b[39m.\u001b[39mupsert(\n\u001b[0;32m    140\u001b[0m         vectors\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m ]\n\u001b[0;32m    149\u001b[0m [res\u001b[39m.\u001b[39mget() \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m async_res]\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:84\u001b[0m, in \u001b[0;36mPinecone._embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding, Embeddings):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding\u001b[39m.\u001b[39;49membed_documents(\u001b[39mlist\u001b[39;49m(texts))\n\u001b[0;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\embeddings\\openai.py:669\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m engine \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n\u001b[1;32m--> 669\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\embeddings\\openai.py:495\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    493\u001b[0m batched_embeddings: List[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 495\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    496\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    497\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[0;32m    498\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    500\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    501\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdict()\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\langchain\\embeddings\\openai.py:117\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m _is_openai_v1():\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    118\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    120\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\resources\\embeddings.py:105\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     99\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    100\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    106\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    107\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[0;32m    108\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    109\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[0;32m    110\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[0;32m    111\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[0;32m    112\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    113\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[0;32m    114\u001b[0m     ),\n\u001b[0;32m    115\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:1086\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1073\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1074\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1082\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1083\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1084\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1085\u001b[0m     )\n\u001b[1;32m-> 1086\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:846\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    838\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    839\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    844\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    845\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    847\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    848\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    849\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    850\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    851\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    852\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:884\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    883\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    885\u001b[0m         options,\n\u001b[0;32m    886\u001b[0m         cast_to,\n\u001b[0;32m    887\u001b[0m         retries,\n\u001b[0;32m    888\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    890\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:956\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    957\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    958\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    959\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    960\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    961\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    962\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:884\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    883\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    885\u001b[0m         options,\n\u001b[0;32m    886\u001b[0m         cast_to,\n\u001b[0;32m    887\u001b[0m         retries,\n\u001b[0;32m    888\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    890\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:956\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    957\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    958\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    959\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    960\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    961\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    962\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\Savag\\AppData\\Local\\anaconda3\\envs\\mad_scientist\\Lib\\site-packages\\openai\\_base_client.py:898\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m    896\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 898\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    900\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# create the vector store\n",
    "vector_store = Pinecone.from_texts(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating LLM based off of bloom model from Huggingface\n",
    "\n",
    "* from BigScience Workshop. \n",
    "* architecture of Bloom similar to GPT3, trained on 46 different languages and 13 programming languages.\n",
    "* https://huggingface.co/docs/transformers/model_doc/bloom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Savag\\.conda\\envs\\nscc_env\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# get the BLOOm Model from HuggingFace\n",
    "llm = HuggingFaceHub(repo_id=\"bigscience/bloom\",\n",
    "                     model_kwargs={\"temperature\":0.1,\n",
    "                                   \"max_length\":100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitter\n",
    "* simple splitting the text by each character.\n",
    "* https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PyPDFLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Savag\\Desktop\\Laboratory\\Github\\emergTech-llm-qa-pdf\\main.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# loading in document\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pdf_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./docs/albert_einstein_relativity.pdf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loader \u001b[39m=\u001b[39m PyPDFLoader(pdf_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m doc \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# split the doc into \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Savag/Desktop/Laboratory/Github/emergTech-llm-qa-pdf/main.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# chunk size is the number of characters\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PyPDFLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# loading in document\n",
    "pdf_path = \"./docs/albert_einstein_relativity.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "doc = loader.load()\n",
    "\n",
    "# split the doc into \n",
    "# chunk size is the number of characters\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "* translating the chunk of texts to series of numbers (embeddings)\n",
    "* using a pre-trained model for generating the embeddings\n",
    "* resource:[\"https://pub.aimind.so/llm-embeddings-explained-simply-f7536d3d0e4b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB\n",
    "* https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "* resource:[\"https://www.pinecone.io/learn/vector-database/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectorestore to use index\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    retriever = db.as_retriever(search_type=\"similarity\",\n",
    "                                search_kwargs={\"k\": 3} \n",
    "                                )\n",
    "except Exception as e:\n",
    "    print(\"error: \", e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    # Initialize RetrievalQA with the required parameters\n",
    "    # Note: return_scores is removed as it's not a valid parameter\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    # Print any error that occurs during the initialization\n",
    "    print(\"error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred:  (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 38563f94-80e1-4725-bb77-d4482160f515)')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ask a question\n",
    "    question = \"what is relativity?\"\n",
    "    answers = qa({\"query\":question})\n",
    "\n",
    "    # print the type and value of answers\n",
    "    # print(type(answers))\n",
    "    # print(answers.keys())\n",
    "    print(answers[\"query\"])\n",
    "    \n",
    "    print(answers[\"result\"])    \n",
    "    \n",
    "    #print(answers)\n",
    "except Exception as e:\n",
    "    # Print any error that occurs during the execution\n",
    "    print(\"An error occurred: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nscc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
